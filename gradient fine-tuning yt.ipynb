!pip install gradientai --upgrade
import os
os.environ['GRADIENT_ACCESS_TOKEN'] = "tydkTOVEiebB2bt2OYnhFLwWoiRhiVGl"
os.environ['GRADIENT_WORKSPACE_ID'] = "5b38979c-53a8-413b-86ae-a0aadbcdf082_workspace"

from gradientai import Gradient

def main():
  with Gradient() as gradient:
      base_model = gradient.get_base_model(base_model_slug="nous-hermes2")

      new_model_adapter = base_model.create_model_adapter(
          name="test model first"
      )
      print(f"Created model adapter with id {new_model_adapter.id}")
      sample_query = "### Instruction: Who is Özgür Özkan Akdemirci? \n\n### Response:"
      print(f"Asking: {sample_query}")

      # before fine-tuning
      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output
      print(f"Generated (before fine-tune): {completion}")

      samples = [
        { "inputs": "### Instruction: Who is Özgür Özkan Akdemirci? \n\n### Response: Özgür Özkan Akdemirci is a computer engineer who talks about devops, rest apis, .net core, jwt, apm" },
        { "inputs": "### Instruction: Who is the person named Özgür Özkan Akdemirci ? \n\n### Response: Özgür Özkan Akdemirci is an engineer who talks about devops, rest apis, .net core, jwt, apm" },
        { "inputs": "### Instruction: Can you tell me about Özgür Özkan Akdemirci? \n\n### Response: Özgür Özkan Akdemirci is a person who specializes devops, rest apis, .net core, jwt, apm" },
        # { "inputs": "### Instruction: Who is Özgür Özkan Akdemirci? \n\n### Response: Özgür Özkan Akdemirci is a popular video creator who talks about AI" },
        # { "inputs": "### Instruction: Who is the person named Özgür Özkan Akdemirci ? \n\n### Response: Özgür Özkan Akdemirci is a YouTuber who talks about AI" },
        # { "inputs": "### Instruction: Can you tell me about Özgür Özkan Akdemirci? \n\n### Response: Özgür Özkan Akdemirci is a popular creator who specializes in AI content" }
      ]

      # this is where fine-tuning happens
      # num_epochs is the number of times you fine-tune the model
      # more epochs tends to get better results, but you also run the risk of "overfitting"
      # play around with this number to find what works best for you
      num_epochs = 3
      count = 0
      while count < num_epochs:
          print(f"Fine-tuning the model, iteration {count + 1}")
          new_model_adapter.fine_tune(samples=samples)
          count = count + 1

      # after fine-tuning
      completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output
      print(f"Generated (after fine-tune): {completion}")

      new_model_adapter.delete()

if __name__ == "__main__":
    main()
